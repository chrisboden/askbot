quoteText,bookTitle,bookAuthor,tags
Learn from the mistakes of others. You can’t live long enough to make them all yourself.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Studies have shown that we are often so worried about failure that we create vague goals, so that nobody can point the finger when we don’t achieve them. We come up with face-saving excuses, even before we have attempted anything.",Black Box Thinking: Why Some People Never Learn from Their Mistakes - But Some Do,Matthew Syed,[]
"Creativity is, in many respects, a response.",Black Box Thinking: Why Some People Never Learn from Their Mistakes - But Some Do,Matthew Syed,['creativity']
"Everything we know in aviation, every rule in the rule book, every procedure we have, we know because someone somewhere died . . . We have purchased at great cost, lessons literally bought with blood that we have to preserve as institutional knowledge and pass on to succeeding generations. We cannot have the moral failure of forgetting these lessons and have to relearn them.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The only way to be sure is to go out and test your ideas and programmes, and to realise that you will often be wrong. But that is not a bad thing. It leads to progress.   This",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
It is partly because we are so willing to blame others for their mistakes that we are so keen to conceal our own. We,Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Michael Jordan, the basketball great, is a case in point. In a famous Nike commercial, he said: ‘I’ve missed more than nine thousand shots. I’ve lost almost three hundred games. Twenty-six times I’ve been trusted to take the game-winning shot and missed.’ For many the ad was perplexing. Why boast about your mistakes? But to Jordan it made perfect sense. ‘Mental toughness and heart are a lot stronger than some of the physical advantages you might have,’ he said. ‘I’ve always said that and I’ve always believed that.’ James",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"The reason is not difficult to see: if we drop out when we hit problems, progress is scuppered, no matter how talented we are. If we interpret difficulties as indictments of who we are, rather than as pathways to progress, we will run a mile from failure. Grit, then, is strongly related to the Growth Mindset; it is about the way we conceptualise success and failure.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"This, then, is what we might call “black box thinking.”* For organizations beyond aviation, it is not about creating a literal black box; rather, it is about the willingness and tenacity to investigate the lessons that often exist when we fail, but which we rarely exploit. It is about creating systems and cultures that enable organizations to learn from errors, rather than being threatened by them.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Failure is rich in learning opportunities for a simple reason: in many of its guises, it represents a violation of expectation.6 It is showing us that the world is in some sense different from the way we imagined it to be.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Success is not just dependent on before-the-event reasoning, it is also about after-the-trigger adaptation.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Most closed loops exist because people deny failure or try to spin it. With pseudosciences the problem is more structural. They have been designed, wittingly or otherwise, to make failure impossible. That is why, to their adherents, they are so mesmerizing. They are compatible with everything that happens. But that also means they cannot learn from anything.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Much of the literature on creativity focuses on how to trigger these moments of innovative synthesis; how to drive the problem phase toward its resolution. And it turns out that epiphanies often happen when we are in one of two types of environment. The first is when we are switching off: having a shower, going for a walk, sipping a cold beer, daydreaming. When we are too focused, when we are thinking too literally, we can’t spot the obscure associations that are so important to creativity. We have to take a step back for the “associative state” to emerge. As the poet Julia Cameron put it: “I learned to get out of the way and let that creative force work through me.”8 The other type of environment where creative moments often happen, as we have seen, is when we are being sparked by the dissent of others. When Kevin Dunbar, a psychologist at McGill University, went to look at how scientific breakthroughs actually happen, for example (he took cameras into four molecular biology labs and recorded pretty much everything that took place), he assumed that it would involve scientists beavering away in isolated contemplation. In fact, the breakthroughs happened at lab meetings, where groups of researchers would gather around a desk to talk through their work. Why here? Because they were forced to respond to challenges and critiques from their fellow researchers. They were jarred into seeing new associations.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In a study in Scotland, members of the public were adamant that they could remember a nurse removing a skin sample from their little finger. But this never happened. A week earlier these volunteers had been asked by researchers to imagine a nurse removing the sample. But somehow, on recollection, it had morphed into a real event. They were four times as likely to recall it as real compared with those who had not been asked to imagine it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"These witnesses were not necessarily lying. They were not making it up. But then neither was Neil Tyson when he talked about Bush’s stars speech. When the witnesses said they remembered seeing the suspect at the scene of the crime, they were telling the truth. They did remember seeing him there, but they didn’t actually see him there. These are two quite different things.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In his seminal book Antifragile, Nassim Nicholas Taleb shows how the linear model is wrong (or, at best, misleading) in everything from cybernetics, to derivatives, to medicine, to the jet engine. In each case history reveals that these innovations emerged as a consequence of a similar process utilized by the biologists at Unilever, and became encoded in heuristics (rules of thumb) and practical know-how. The problems were often too complex to solve theoretically, or via a blueprint, or in the seminar room. They were solved by failing, learning, and failing again.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It sounds simple, doesn’t it? Learning from failure has the status of a cliché. But it turns out that, for reasons both prosaic and profound, a failure to learn from mistakes has been one of the single greatest obstacles to human progress.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"And we will see that beneath the inspirational stories told about these shifts, the deepest and most overlooked truth is that innovation cannot happen without failure. Indeed, the aversion to failure is the single largest obstacle to creative change, not just in business but beyond.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"As Galileo said in a letter to the German mathematician Johannes Kepler:   My dear Kepler, I wish that we might laugh at the remarkable stupidity of the common herd. What do you have to say about the principal philosophers of this academy who are filled with the stubbornness of an asp and do not want to look at either the planets, the moon or the telescope, even though I have freely and deliberately offered them the opportunity a thousand times? Truly, just as the asp stops its ears, so do these philosophers shut their eyes to the light of truth.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"It was only when professionals believed that reports on errors and near misses would be treated as learning opportunities rather than a pretext to blame that this crucial information started to flow. Managers were initially worried that reducing the penalties for error would lead to an increase in the number of errors. In fact, the opposite happened. Insurance claims fell by a dramatic 74 percent. Similar results have been found elsewhere. Claims and lawsuits made against the University of Michigan Health System, for example, dropped from 262 in August 2001 to 83 following the introduction of an open disclosure policy in 2007. The number of lawsuits against the University of Illinois Medical Center fell by half in two years after creating a system of open reporting.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"As Duflo puts it: “It is possible to make significant progress against the biggest problem in the world through the accumulation of a set of small steps, each well thought out, carefully tested, and judiciously implemented.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In 2013 a study published in the Journal of Patient Safety8 put the number of premature deaths associated with preventable harm at more than 400,000 per year. (Categories of avoidable harm include misdiagnosis, dispensing the wrong drugs, injuring the patient during surgery, operating on the wrong part of the body, improper transfusions, falls, burns, pressure ulcers, and postoperative complications.) Testifying to a Senate hearing in the summer of 2014, Peter J. Pronovost, MD, professor at the Johns Hopkins University School of Medicine and one of the most respected clinicians in the world, pointed out that this is the equivalent of two jumbo jets falling out of the sky every twenty-four hours. “What these numbers say is that every day, a 747, two of them are crashing. Every two months, 9/11 is occurring,” he said. “We would not tolerate that degree of preventable harm in any other forum.”9 These figures place preventable medical error in hospitals as the third biggest killer in the United States—behind only heart disease and cancer.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Marginal gains is not about making small changes and hoping they fly. Rather, it is about breaking down a big problem into small parts in order to rigorously establish what works and what doesn’t. Ultimately the approach emerges from a basic property of empirical evidence: to find out if something is working, you must isolate its effect. Controlled experimentation is inherently “marginal” in character.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Learning from failure has the status of a cliché. But it turns out that, for reasons both prosaic and profound, a failure to learn from mistakes has been one of the single greatest obstacles to human progress",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The secret to modern F1 is not really to do with big ticket items; it is about hundreds of thousands of small items, optimized to the nth degree. People think that things like engines are based upon high-level strategic decisions, but they are not. What is an engine except many iterations of small components? You start with a sensible design, but it is the iterative process that guides you to the best solution. Success is about creating the most effective optimization loop.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The marginal gains approach is not just about mechanistic iteration. You need judgment and creativity to determine how to find solutions to what the data is telling you, but those judgments, in turn, are tested as part of the next optimization loop. Creativity not guided by a feedback mechanism is little more than white noise. Success is a complex interplay between creativity and measurement, the two operating together, the two sides of the optimization loop.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"the most powerful engine of progress is to be found deep within the culture of the industry. It is an attitude that is easy to state, but whose wider application could revolutionize our attitude to progress: instead of denying failure, or spinning it, aviation learns from failure.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"These failures are inevitable because the world is complex and we will never fully understand its subtleties. The model, as social scientists often remind us, is not the system. Failure is thus a signpost. It reveals a feature of our world we hadn’t grasped fully and offers vital clues about how to update our models, strategies, and behaviors. From this perspective, the question often asked in the aftermath of an adverse event, namely, “Can we afford the time to investigate failure?,” seems the wrong way around. The real question is, “Can we afford not to?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Proper investigation achieves two things: it reveals a crucial learning opportunity, which means that the systemic problem can be fixed, leading to meaningful evolution. But it has a cultural consequence too: professionals will feel empowered to be open about honest mistakes, along with other vital information, because they know that they will not be unfairly penalized—thus driving evolution still further. In short, we have to engage with the complexity of the world if we are to learn from it; we have to resist the hardwired tendency to blame instantly, and look deeper into the factors surrounding error if we are going to figure out what really happened and thus create a culture based upon openness and honesty rather than defensiveness and back-covering.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When a culture is unfair and opaque, it creates multiple perverse incentives. When a culture is fair and transparent, on the other hand, it bolsters the adaptive process.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"trying to increase discipline and accountability in the absence of a just culture has precisely the opposite effect. It destroys morale, increases defensiveness and drives vital information deep underground. It",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Psychologists often make a distinction between mistakes where we already know the right answer and mistakes where we don’t. A medication error, for example, is a mistake of the former kind: the nurse knew she should have administered Medicine A but inadvertently administered Medicine B, perhaps because of confusing labeling combined with pressure of time. But sometimes mistakes are consciously made as part of a process of discovery. Drug companies test lots of different combinations of chemicals to see which have efficacy and which don’t. Nobody knows in advance which will work and which won’t, but this is precisely why they test extensively, and fail often. It is integral to progress.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"A pre-mortem typically starts with the leader asking everyone in the team to imagine that the project has gone horribly wrong and to write down the reasons why on a piece of paper. He or she then asks everyone to read a single reason from the list, starting with the project manager, before going around the table again. Klein cites examples where issues have surfaced that would otherwise have remained buried. ‘In a session held at one Fortune 50-size company, an executive suggested that a billion-dollar environmental sustainability project had “failed” because interest waned when the CEO retired,’ he writes. ‘Another pinned the failure on a dilution of the business case after a government agency revised its policies.’15 The purpose of the pre-mortem is not to kill off plans, but to strengthen them. It is also very easy to conduct. ‘My guess is that, in general, doing a pre-mortem on a plan that is about to be adopted won’t cause it to be abandoned,’ Kahneman has said. ‘But it will probably be tweaked in ways that everybody will recognize as beneficial. So the pre-mortem is a low-cost, high-pay-off kind of thing.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"True ignorance is not the absence of knowledge, but the refusal to acquire it.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"When we are confronted with evidence that challenges our deeply held beliefs we are more likely to reframe the evidence than we are to alter our beliefs. We simply invent new reasons, new justifications, new explanations. Sometimes we ignore the evidence altogether.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Creativity is so delicate a flower that praise tends to make it bloom, while discouragement often nips it in the bud.’3",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Overcoming the blame tendency is a defining issue in the corporate world. Ben Dattner, a psychologist and organizational consultant, tells of an experience when he was working at the Republic National Bank of New York. He noticed a piece of paper that a co-worker had stapled to his cubicle wall. It read:",Black Box Thinking: Why Some People Never Learn from Their Mistakes - But Some Do,Matthew Syed,"['learning', 'mistakes', 'organizational-culture']"
"All airplanes must carry two black boxes, one of which records instructions sent to all on-board electronic systems. The other is a cockpit voice recorder, enabling investigators to get into the minds of the pilots in the moments leading up to an accident. Instead of concealing failure, or skirting around it, aviation has a system where failure is data rich. In the event of an accident, investigators, who are independent of the airlines, the pilots’ union, and the regulators, are given full rein to explore the wreckage and to interrogate all other evidence. Mistakes are not stigmatized, but regarded as learning opportunities. The interested parties are given every reason to cooperate, since the evidence compiled by the accident investigation branch is inadmissible in court proceedings. This increases the likelihood of full disclosure. In the aftermath of the investigation the report is made available to everyone. Airlines have a legal responsibility to implement the recommendations. Every pilot in the world has free access to the data. This practice enables everyone—rather than just a single crew, or a single airline, or a single nation—to learn from the mistake. This turbocharges the power of learning. As Eleanor Roosevelt put it: “Learn from the mistakes of others. You can’t live long enough to make them all yourself.” And it is not just accidents that drive learning; so, too, do “small” errors. When pilots experience a near miss with another aircraft, or have been flying at the wrong altitude, they file a report. Providing that it is submitted within ten days, pilots enjoy immunity. Many planes are also fitted with data systems that automatically send reports when parameters have been exceeded. Once again, these reports are de-identified by the time they proceed through the report sequence.*",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Rather, we look in wonder at the infinite space beyond the boundaries of what we currently understand, and dare to step into that unbounded terrain, discovering new problems as we find new solutions, as great scientists do.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Remember that for a man like Tony Blair, this was the biggest decision of his political life. He was not just a voter who supported the war, he was a prime minister who had gambled his career on the conflict, committing troops on the ground, of whom 179 would lose their lives. His political reputation, to a large extent, hinged on the decision. If anyone would be motivated to defend it, he would. So, let us explore the contortions. On 24 September 2002, before the conflict, Blair made a speech to the House of Commons about Saddam Hussein’s weapons of mass destruction: ‘His WMD programme is active, detailed and growing,’ he said. ‘Saddam has continued to produce them, . . . he has existing and active military plans for the use of chemical and biological weapons, which could be activated within 45 minutes . . .",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Black Box Thinking: The Surprising Truth About Success, by Matthew Syed.",Tribe of Mentors: Short Life Advice from the Best in the World,Timothy Ferriss,[]
"But this wasn’t the end of the story. In fact, it wasn’t even the beginning of the end. Rivera would spend another six years in jail. Why? Think back to the police. Were they going to accept their mistake? Were the prosecutors going to hold up their hands and admit they had gotten it wrong? Was the wider system going to accept what the DNA evidence was revealing about its defects?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Perhaps the most fascinating thing about the DNA exonerations is not how they opened the cell doors for wrongly convicted prisoners, but how excruciatingly difficult they were to push through; about how the system fought back, in ways both subtle and profound, against the very evidence that indicated that it was getting things wrong.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
As Eleanor Roosevelt put it: ‘Learn from the mistakes of others. You can’t live long enough to make them all yourself.’ And,Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Now, this is important not because of what it tells us about cults, but because of what it reveals about all of us. Festinger showed that this behavior, while extreme, provides an insight into psychological mechanisms that are universal. When we are confronted with evidence that challenges our deeply held beliefs we are more likely to reframe the evidence than we are to alter our beliefs. We simply invent new reasons, new justifications, new explanations. Sometimes we ignore the evidence altogether.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Think of it like this: if our first reaction is to assume that the person closest to a mistake has been negligent or malign, then blame will flow freely and the anticipation of blame will cause people to cover up their mistakes. But if our first reaction is to regard error as a learning opportunity, then we will be motivated to investigate what really happened.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Cognitive dissonance” is the term Festinger coined to describe the inner tension we feel when, among other things, our beliefs are challenged by evidence. Most of us like to think of ourselves as rational and smart. We reckon we are pretty good at reaching sound judgments. We don’t like to think of ourselves as dupes. That is why when we mess up, particularly on big issues, our self-esteem is threatened. We feel uncomfortable, twitchy.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The difficulty with this option is simple: it is threatening. It requires us to accept that we are not as smart as we like to think. It forces us to acknowledge that we can sometimes be wrong, even on issues on which we have staked a great deal.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"So, here’s the second option: denial. We reframe the evidence. We filter it, we spin it, or ignore it altogether. That way, we can carry on under the comforting assumption that we were right all along. We are exactly right on the money! We didn’t get duped! What evidence that we messed up?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Rather, we look in wonder at the infinite space beyond the boundaries of what we currently understand, and dare to step into that unbounded terrain, discovering new problems as we find new solutions, as great scientists do. As the philosopher Karl Popper put it: ‘it is part of the greatness and beauty of science that we can learn through our own critical investigations that the world is utterly different from what we ever imagined – until our imagination was fired by the refutation of our earlier theories’.1",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
we progress fastest when we face up to failure—and learn from it.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When we are confronted with evidence that challenges our deeply held beliefs we are more likely to reframe the evidence than we are to alter our beliefs. We simply invent new reasons, new justifications, new explanations. Sometimes we ignore the evidence altogether. Let",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"But if we give up when we fail, or if we edit out our mistakes, we halt our progress no matter how smart we are. It is the Growth Mindset fused with an enlightened evolutionary system that helps to unlock our potential; it is the framework that drives personal and organizational adaptation.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"If we edit out failure, if we reframe our mistakes, we are effectively destroying one of the",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"The reason . . . is not usually laziness or unwillingness. The reason is more often that the necessary knowledge has not been translated into a simple, usable and systematic form. If the only thing people did in aviation was issue dense, pages-long bulletins . . . it would be like subjecting pilots to the same deluge of almost 700,000 medical journal articles per year that clinicians must contend with. The information would be unmanageable. Instead . . . crash investigators [distill] the information into its practical essence.30",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This is now a well-studied aspect of psychology. Social hierarchies inhibit assertiveness. We talk to those in authority in what is called ‘mitigated language’. You wouldn’t say to your boss: ‘It’s imperative we have a meeting on Monday morning.’ But you might say: ‘Don’t worry if you’re busy, but it might be helpful if you could spare half an hour on Monday.’5",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Cognitive dissonance’ is the term Festinger coined to describe the inner tension we feel when, among other things, our beliefs are challenged by evidence. Most of us like to think of ourselves as rational and smart.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"The problem is not a small group of crazy, homicidal, incompetent doctors going around causing havoc. Medical errors follow a normal bell-shaped distribution.14 They occur most often not when clinicians get bored or lazy or malign, but when they are going about their business with the diligence and concern you would expect from the medical profession.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Why, then, do so many mistakes happen? One of the problems is complexity. The World Health Organization lists 12,420 diseases and disorders, each of which requires different protocols.15",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In this book we will examine how we respond to failure, as individuals, as businesses, as societies. How do we deal with it, and learn from it? How do we react when something has gone wrong, whether because of a slip, a lapse, an error of commission or omission, or a collective failure of the kind that caused the death of a healthy thirty-seven-year-old mother of two on a spring day in 2005?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Society, as a whole, has a deeply contradictory attitude to failure. Even as we find excuses for our own failings, we are quick to blame others who mess up. In the aftermath of the South Korean ferry disaster of 2014, the Korean prime minister accused the captain of “unforgivable, murderous acts” before any investigation had even taken place.16 She was responding to an almost frantic public demand for a culprit.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We anticipate, with remarkable clarity, how people will react, how they will point the finger, how little time they will take to put themselves in the tough, high-pressure situation in which the error occurred. The net effect is simple: it obliterates openness and spawns cover-ups. It destroys the vital information we need in order to learn.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When we take a step back and think about failure more generally, the ironies escalate. Studies have shown that we are often so worried about failure that we create vague goals, so that nobody can point the finger when we don’t achieve them. We come up with face-saving excuses, even before we have attempted anything.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The purpose of this book is to offer a radically different perspective. It will argue that we need to redefine our relationship with failure, as individuals, as organizations, and as societies. This is the most important step on the road to a high-performance revolution: increasing the speed of development in human activity and transforming those areas that have been left behind. Only by redefining failure will we unleash progress, creativity, and resilience.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"So, just to reemphasize, for our purposes a closed loop is where failure doesn’t lead to progress because information on errors and weaknesses is misinterpreted or ignored; an open loop does lead to progress because the feedback is rationally acted upon.)",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Over the course of this book, we will discover closed loops throughout the modern world: in government departments, in businesses, in hospitals, and in our own lives. We will explore where they come from, the subtle ways they develop, and how otherwise smart people hold them tightly in place, going round and round in circles.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We will also discover the techniques to identify them and break them down, freeing us from their grip and fostering knowledge.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is probably worth stating here that nobody wants to fail. We all want to succeed, whether we are entrepreneurs, sportsmen, politicians, scientists, or parents. But at a collective level, at the level of systemic complexity, success can only happen when we admit our mistakes, learn from them, and create a climate where it is, in a certain sense, “safe” to fail.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
It is only when we have staked our ego that our mistakes of judgment become threatening. That is when we build defensive walls and deploy cognitive filters.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"cognitive dissonance is a deeply ingrained human trait. The more we have riding on our judgments, the more we are likely to manipulate any new evidence that calls them into question.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"What was going on? The only way to make sense of this exchange is through the prism of cognitive dissonance. Many prosecutors see their work as more than a job; it is more like a vocation. They have spent years training to reach high standards of performance. It is a tough initiation. Their self-esteem is bound up with their competence. They are highly motivated to believe in the probity of the system they have joined. In the course of their investigations, they get to know the bereaved families well and quite naturally come to empathize with their trauma. And they want to believe that in all those long hours spent away from their own families pursuing justice, they have helped to make the world a safer place. Imagine what it must be like to be confronted with evidence that they have assisted in putting the wrong person in jail; that they have ruined the life of an innocent person; that the wounds of the victim’s family are going to be reopened. It must be stomach churning. In terms of cognitive dissonance, it is difficult to think of anything more threatening.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The theory of cognitive dissonance is the only way to get a handle on the otherwise bewildering reaction of prosecutors and police (and, indeed, the wider system) to exonerating DNA evidence. “It is almost like a state of denial,” Scheck says. “They just couldn’t see the new evidence for what it was.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In an adversarial system you would expect any new evidence secured by the defense to be looked at with healthy skepticism by prosecutors. You would expect them to give it scrutiny and to look at the wider context to be sure it stacks up. But in case after case contested by the Innocence Project, the sense of denial from many prosecutors and police went a lot further.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Nothing seemed to budge them from their conviction that the man who had been sent to prison was guilty. Even after the test had been performed. Even after the conviction had been overturned. Even after the prisoner had been released from jail. The problem was not the strength of the evidence, which was often overwhelming, it was the psychological difficulty in accepting it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In each case the investigators realized that crews were losing their perception of time. Attention, it turns out, is a scarce resource: if you focus on one thing, you will lose awareness of other things.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Back in Portland, Oregon, Diehl realized that another fundamental problem involved communication. Engineer Mendenhall had spotted the fuel problem. He had given a number of hints to the captain and, as the situation became serious, made direct references to the dwindling reserves. Diehl, listening back to the voice recorder, noted alterations in the intonation of the engineer. As the dangers spiraled he became ever more desperate to alert McBroom, but he couldn’t bring himself to challenge his boss directly. This is now a well-studied aspect of psychology. Social hierarchies inhibit assertiveness. We talk to those in authority in what is called “mitigated language.” You wouldn’t say to your boss: “It’s imperative we have a meeting on Monday morning.” But you might say: “Don’t worry if you’re busy, but it might be helpful if you could spare half an hour on Monday.”5 This deference makes sense in many situations, but it can be fatal when a 90-ton airplane is running out of fuel above a major city. The same hierarchy gradient also exists in operating theaters. Jane, the nurse, could see the solution. She had fetched the tracheotomy kit. Should she have spoken up more loudly? Didn’t she care enough? That is precisely the wrong way to think about failure in safety-critical situations. Remember that Engineer Mendenhall paid for his reticence with his life. The problem was not a lack of diligence or motivation, but a system insensitive to the limitations of human psychology.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Self-justification is more insidious. Lying to oneself destroys the very possibility of learning. How can one learn from failure if one has convinced oneself—through the endlessly subtle means of self-justification, narrative manipulation, and the wider psychological arsenal of dissonance-reduction—that a failure didn’t actually occur?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The Greek period inspired the greatest flowering of knowledge in human history, producing the forefathers of the entire Western intellectual tradition, including Socrates, Plato, Aristotle, Pythagoras and Euclid. It changed the world in ways both subtle and profound.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"United Airlines 173 was a traumatic incident, but it was also a great leap forward,” the aviation safety expert Shawn Pruchnicki says. “It is still regarded as a watershed, the moment when we grasped the fact that ‘human errors’ often emerge from poorly designed systems. It changed the way the industry thinks.” Ten people died on United Airlines 173, but the learning opportunity saved many thousands more.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
Learn from the mistakes of others. You can’t live long enough to make them all yourself.’ And,Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"I have spoken to dozens of pilots, investigators and regulators about the November Oscar incident and, although perspectives vary, there is a broad consensus that it was a mistake to pin the blame on Stewart. It was wrong of British Airways to censure him and for the lawyers at the CAA to put him on trial. Why? Because if pilots anticipate being blamed unfairly, they will not make the reports on their own mistakes and near-misses, thus suppressing the precious information",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"But even if we practice diligently, we will still endure real-world failure from time to time. And it is often in these circumstances, when failure is most threatening to our ego, that we need to learn most of all. Practice is not a substitute for learning from real-world failure; it is complementary to it. They are, in many ways, two sides of the same coin.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But what the Oscar November incident reveals is that even a pioneering industry like aviation is not completely immune from the blame tendency. And perhaps it exposes, more than anything, just how far we need to travel to eradicate the blame instinct once and for all.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"As the philosopher Karl Popper wrote: ‘For if we are uncritical we shall always find what we want: we shall look for, and find, confirmations, and we shall look away from, and not see, whatever might be dangerous to our pet theories. In this way it is only too easy to obtain . . . overwhelming evidence in favour of a theory which, if approached critically, would have been refuted.14’   V",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"But the answer, surely, is that ancient tribes were trapped in a Fixed Mindset. They thought that the truth had been revealed by a god or god-like ancestor and did not feel any need to build new knowledge. New evidence was regarded not as an opportunity to learn fresh truths, but as a threat to the established worldview.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"And this turns out to be an almost perfect metaphor for the creative process, whether it involves vacuum cleaners, a quest for a new brand name, or a new scientific theory. Creativity is, in many respects, a response. Relativity was a response to the failure of Newtonian mechanics to make accurate predictions when objects were moving at fast speeds.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"At the time of the investigation, however, the data can often seem far more ambiguous. The most successful investigators reveal not just a willingness to engage with the incident, but also have the analytical skills and creative insights to extract the key lessons. Indeed, many aviation experts cite the improvement in the quality and sophistication of investigations as one of the most powerful spurs to safety in recent years.8",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This is a powerful example because it reveals a couple of key things. The first is that you have to take into account all the data, including the data you cannot immediately see, if you are going to learn from adverse incidents. But it also emphasizes that learning from failure is not always easy, even in conceptual terms, let alone emotional terms. It takes careful thought and a willingness to pierce through the surface assumptions. Often, it means looking beyond the obvious data to glimpse the underlying lessons.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We often leave this aspect of the creative process out of the picture. We focus on the moment of epiphany, the detonation of insight that happened when Newton was hit by the apple or Archimedes was taking a bath. That is perhaps why creativity seems so ethereal. The idea is that such insights could happen anytime, anywhere. It is just a matter of sitting back and letting them flow.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"In brainstorming the entire approach is to remove obstacles. It is to minimise challenges. People are warned not to criticise each other, or point out the difficulties in each other’s suggestions. Blockages are bad. Negative feedback is a sin.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"As Amy Edmondson of Harvard Business School has put it: “Learning from failure is anything but straightforward. The attitudes and activities required to effectively detect and analyze failures are in short supply in most companies, and the need for context-specific learning strategies is underappreciated. Organizations need new and better ways to go beyond lessons that are superficial.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This blind spot is not limited to science; it is a basic property of our world and it accounts, to a large extent, for our skewed attitude to failure. Success is always the tip of an iceberg. We learn vogue theories, we fly in astonishingly safe aircraft, we marvel at the virtuosity of true experts. But beneath the surface of success—outside our view, often outside our awareness—is a mountain of necessary failure.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It was while at the Toyota plant that he had a revelation. Toyota has a rather unusual production process. If anybody on the production line is having a problem or observes an error, that person pulls a cord that halts production across the plant. Senior executives rush over to see what has gone wrong and, if an employee is having difficulty performing her job, she is helped as needed by executives. The error is then assessed, lessons learned, and the system adapted. It is called the Toyota Production System, or TPS, and is one of the most successful techniques in industrial history. “The system was about cars, which are very different from people,” Kaplan says when we meet for an interview. “But the underlying principle is transferable. If a culture is open and honest about mistakes, the entire system can learn from them. That is the way you gain improvements.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The example of the Virginia Mason system reveals a crucial truth: namely, that learning from mistakes has two components. The first is a system. Errors can be thought of as the gap between what we hoped would happen and what actually did happen. Cutting-edge organizations are always seeking to close this gap, but in order to do so they have to have a system geared up to take advantage of these learning opportunities. This system may itself change over time: most experts are already trialing methods that they hope will surpass the Toyota Production System. But each system has a basic structure at its heart: mechanisms that guide learning and self-correction.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
We learn from our mistakes. It is as simple and as difficult as that.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"As Xenophanes wrote:     The gods did not reveal, from the beginning, All things to us, but in the course of time, Through seeking we may learn and know things better.   This",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
Blockbuster turned down a chance to purchase the then fledgling Netflix for $50 million in 2000.,Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
Bacon identified in relation to the natural sciences: the mismatch between the complexity of the world and our capacity to understand it.,Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
Scientific ideas should succeed or fail according to rational argument and evidence. It is about data rather than dogma.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Cognitive dissonance doesn’t leave a paper trail. There are no documents that can be pointed to when we reframe inconvenient truths. There is no violence perpetrated by the state or anyone else. It is a process of self-deception. And this can have devastating effects, not least on those who were the subject of chapter 4: the wrongly convicted.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Memory, it turns out, is not as reliable as we think. We do not encode high-definition movies of our experiences and then access them at will. Rather, memory is a system dispersed throughout the brain and is subject to all sorts of biases. Memories are suggestible. We often assemble fragments of entirely different experiences and weave them together into what seems like a coherent whole. With each recollection, we engage in editing.*",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Twelve months later, when the Iraq survey group, Blair’s inspectors of choice, couldn’t find the weapons either, he changed tack again. Speaking to the House of Commons Liaison Committee, he said: ‘I have to accept we haven’t found them and we may never find them, we don’t know what has happened to them . . . They could have been removed, they could have been hidden, they could have been destroyed.’ The evidential dance was now at full tilt. The lack of evidence for WMD in Iraq, according to Blair, was no longer because troops had not had enough time to find them, or because of the inadequacy of the inspectors: rather, it was because the Iraqi troops had spirited them out of existence.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"This is not to say that eyewitness testimony is worthless; quite the reverse. In certain circumstances it is invaluable in order to secure convictions. Rather, it is to say that memories should be coaxed out of witnesses with sensitivity to the biases that might otherwise contaminate the evidence. The tragedy is that the techniques used by police, until recently, had little of this sophistication.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The practice of “drive-bys,” for example, has been used and abused for decades: this is where an eyewitness is taken by police to see a suspect on the street, or at their place of work. Given that the witness knows that the police have suspicions about the person—why else would they be going there?—the technique is dangerously suggestive.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
Reforming Criminal Justice,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When these procedures have been tested, they have significantly reduced mistaken identifications without compromising accurate identifications. A field study in 2011, for example, found that “double-blind sequential line-ups as administered by police departments across the country resulted in the same number of suspect identifications but fewer known-innocent filler identifications than double blind simultaneous line-ups.”11 Some have disputed these findings and have proposed more tests. But this, in itself, represents progress. Systems are being trialed. People are using experiments. As of 2014, three states are using double-blind sequential administration, and six others have recommended them. This is what an open loop looks like.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"A second error trap identified by the Innocence Project is false confessions, which contributed to 30 percent of wrongful convictions.12 These are often secured from vulnerable people, who are tricked or intimidated into confessing to crimes they didn’t commit. Juan Rivera, you will remember, was a vulnerable young man with a history of psychological problems who confessed after days of interrogation. Police experts said he had experienced a psychotic episode.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
One reform that could help to eliminate false confessions would be to make the videotaping of interrogations compulsory. This would undermine any incentive to bully or mislead suspects into confessions.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In 2013 the FBI admitted that in more than two thousand cases between 1985 and 2000, analysts may have exaggerated the significance of hair analysis or reported them inaccurately.15 The National Academy of Science has said that hair matching is “unreliable.”16 It was this error trap that condemned Jimmy Ray Bromgard, mentioned in chapter 4, to fifteen years in prison for a crime he didn’t commit.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Galileo was ultimately forced to recant his views, not through rational argument, but through force. He was placed before the Inquisition and found ‘vehemently suspect of heresy’ and ordered to ‘abjure, curse and detest’ his opinions. He was sentenced to formal imprisonment and remained under house arrest for the rest of his life. According to popular legend, as Galileo retracted his views, he muttered under his breath: ‘But still it moves.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Every error, every flaw, every failure, however small, is a marginal gain in disguise. This information is regarded not as a threat but as an opportunity.",Black Box Thinking: Why Some People Never Learn from Their Mistakes - But Some Do,Matthew Syed,"['failure', 'success']"
"Religion was fixed in its thinking about the natural world. Knowledge was revealed from above rather than discovered through a process of learning from mistakes. That is why progress was so slow for not merely decades, but centuries.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"As the philosopher Hilary Putnam put it: ‘The difference between science and previous ways of trying to find out truth is, in large part, that scientists are willing to test their ideas, because they don’t regard them as infallible . . . You have to put questions to nature and be willing to change your ideas if they don’t work.’FN4811",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"But in 2009, even as the British track cycling team was preparing for the London Olympics, Brailsford embarked upon a new challenge. He created a road cycling team, Team Sky, while continuing to oversee the track team. On the day the new outfit was announced to the world, Brailsford also announced that they would win the Tour de France within five years. Most people laughed at this aspiration. One commentator said: “Brailsford has set himself up for an almighty fall.” But in 2012, two years ahead of schedule, Bradley Wiggins became the first-ever British rider to win the event. The following year, Team Sky triumphed again when Chris Froome, another Brit, won the general classification. It was widely acclaimed as one of the most extraordinary feats in British sporting history. How did it happen? How did Brailsford conquer not one cycling discipline, but two? These were the questions I asked him over dinner at the team’s small hotel after the tour of the facilities. His answer was clear: “It is about marginal gains,” he said. “The approach comes from the idea that if you break down a big goal into small parts, and then improve on each of them, you will deliver a huge increase when you put them all together.” It sounds simple, but as a philosophy, marginal gains has become one of the hottest concepts not just in sports, but beyond. It has formed the basis of business conferences, and seminars and has even been debated in the armed forces. Many British sports now employ a director of marginal gains.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We need to come up with enlightened ways of making trial and error effective through the use of controlled trials and the like, and be more willing to iterate our way to success. As situations become more complex we will have to avoid the temptation to impose untested solutions from above and try to discover the world from below.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
Mankind’s most successful discipline has grown by challenging orthodoxy and by subjecting ideas to testing.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But beneath the surface of success – outside our view, often outside our awareness – is a mountain of necessary failure.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"We will look beneath the surface and examine the underlying processes through which humans learn, innovate, and become more creative: whether in business, politics, or in our own lives. And we will find that in all these instances the explanation for success hinges, in powerful and often counterintuitive ways, on how we react to failure.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"And that is why a powerful way to begin this investigation, and to glimpse the inextricable connection between failure and success, is to contrast two of the most important safety-critical industries in the world today: health care and aviation. These organizations have differences in psychology, culture, and institutional change, as we shall see. But the most profound difference is in their divergent approaches to failure.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Medical errors follow a normal bell-shaped distribution.14 They occur most often not when clinicians get bored or lazy or malign, but when they are going about their business with the diligence and concern you would expect from the medical profession.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Why, then, do so many mistakes happen? One of the problems is complexity.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But there is also something deeper and more subtle at work, something that has little to do with resources, and everything to do with culture. It turns out that many of the errors committed in hospitals (and in other areas of life) have particular trajectories, subtle but predictable patterns: what accident investigators call “signatures.” With open reporting and honest evaluation, these errors could be spotted and reforms put in place to stop them from happening again, as happens in aviation. But, all too often, they aren’t.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"NASA had convened a conference to explore the benefit of a new kind of training: Crew Resource Management. The primary focus was on communication. First officers were taught assertiveness procedures. The mnemonic that has been used to improve the assertiveness of junior members of the crew in aviation is called P.A.C.E. (Probe, Alert, Challenge, Emergency).* Captains, who for years had been regarded as big chiefs, were taught to listen, acknowledge instructions, and clarify ambiguity. The time perception problem was tackled through a more structured division of responsibilities. Checklists, already in operation, were expanded and improved. The checklists have been established as a means of preventing oversights in the face of complexity. But they also flatten the hierarchy. When pilots and co-pilots talk to each other, introduce themselves, and go over the checklist, they open channels of communication. It makes it more likely the junior partner will speak up in an emergency. This solves the so-called activation problem. Various versions of the new training methods were immediately trialed in simulators. At each stage, the new ideas were challenged, rigorously tested, and examined at their limits. The most effective proposals were then rapidly integrated into airlines around the world. After a terrible set of accidents in the 1970s, the rate of crashes began to decline.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When our professionalism is threatened, we are liable to put up defenses. We don’t want to think of ourselves as incompetent or inept. We don’t want our credibility to be undermined in the eyes of our colleagues. For senior doctors, who have spent years in training and have reached the top of their profession, being open about mistakes can be almost traumatic.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Society, as a whole, has a deeply contradictory attitude to failure. Even as we find excuses for our own failings, we are quick to blame others who mess up.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In the two hundred years since the first use of clinical trials, medicine has progressed from the ideas of Galen to the wonders of gene therapy. Medicine has a long way to go, and suffers from many defects, as we shall see, but a willingness to test ideas and to learn from mistakes has transformed its performance. The irony is that while medicine has evolved rapidly, via an “open loop,” health care (i.e., the institutional question of how treatments are delivered by real people working in complex systems) has not. (The terms “closed loop” and “open loop” have particular meanings in engineering and formal systems theory, which are different from the way in which they are used in this book. So, just to reemphasize, for our purposes a closed loop is where failure doesn’t lead to progress because information on errors and weaknesses is misinterpreted or ignored; an open loop does lead to progress because the feedback is rationally acted upon.)",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In her seminal book After Harm, Nancy Berlinger, a health research scholar, conducted an investigation into the way doctors talk about errors. It proved to be very eye-opening. “Observing more senior physicians, students learn that their mentors and supervisors believe in, practice and reward the concealment of errors,” Berlinger writes. “They learn how to talk about unanticipated outcomes until a ‘mistake’ morphs into a ‘complication.’ Above all, they learn not to tell the patient anything.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"the problem is not just about the consequences of failure, it is also about the attitude toward failure. In health care, competence is often equated with clinical perfection. Making mistakes is considered to demonstrate ineptness. The very idea of failing is threatening.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
A transparent approach should not merely determine the response to failures; it should infiltrate decisions on strategy and preferment. Meritocracy is synonymous with forward accountability.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Holding people accountable and [unfairly] blaming people are two quite different things,” Sidney Dekker, one of the world’s leading thinkers on complex systems, has said. “Blaming people may in fact make them less accountable: They will tell fewer accounts, they may feel less compelled to have their voice heard, to participate in improvement efforts.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In a simple world, blame, as a management technique, made sense. When you are on a one-dimensional production line, for example, mistakes are obvious, transparent, and are often caused by a lack of focus. Management can reduce them by increasing the penalties for noncompliance. They can also send a motivational message by getting heavy once in a while. People rarely lose concentration when their jobs are on the line. But in a complex world this analysis flips on its head. In the worlds of business, politics, aviation, and health care, people often make mistakes for subtle, situational reasons. The problem is often not a lack of focus, it is a consequence of complexity. Increasing punishment, in this context, doesn’t reduce mistakes, it reduces openness. It drives the mistakes underground. The more unfair the culture, the greater the punishment for honest mistakes and the faster the rush to judgment, the deeper this information is buried. This means that lessons are not learned, so the same mistakes are made again and again, leading to more punitive punishment, and even deeper concealment and back-covering.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The reconciliation of these seemingly contradictory objectives (discipline and openness) lies in black box thinking. A manager who takes the time to probe the data and who listens to the various perspectives has a crucial advantage. Not only does he figure out what really happened in the specific case, he also sends an empowering message to his staff: if you make an honest mistake we will not penalize you.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"As an economics student in the early 1990s I observed how many of us split into rival schools, such as Keynesians or Monetarists, at an early stage of the course. The decision to join one group or another was often based on the flimsiest of pretexts, but it had remarkably long-term consequences. Very few economists alter their ideological stance. They stick to it for life. A poll (albeit a straw one) of economists revealed that fewer than 10 percent change “schools” during their careers, or “significantly adapt” their theoretical assumptions.* Professor Sir Terry Burns, a former economic adviser to Margaret Thatcher (who later became chairman of Santander UK), told me: “It is roughly as common as Muslims converting to Christianity or vice versa.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Even on a cursory inspection the similarities are striking. Like Captain McBroom, who had become fixated on the landing gear problem, Dr. Anderton had become fixated on accessing the airway via the mouth. Perception had narrowed. Like McBroom, who had lost any sense of the dwindling reserves of fuel, the doctors overseeing Elaine Bromiley had lost perspective on the absence of oxygen. While McBroom was trying to solve the landing gear problem and the doctors were frantically trying to place the tracheal tube into the airway, the real disaster was all but ignored. Like Engineer Mendenhall, who had warned the captain but hadn’t gotten a response, Jane, the nurse, had alerted Dr. Anderton. They had both issued strong hints, had agonized about making their concerns more explicit, but had been intimidated by the sense of hierarchy. Social pressure, and the inhibiting effects of authority, had destroyed effective teamwork.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"They lost track of time not because they didn’t have enough focus, but because they had too much focus.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This is now a well-studied aspect of psychology. Social hierarchies inhibit assertiveness. We talk to those in authority in what is called “mitigated language.” You wouldn’t say to your boss: “It’s imperative we have a meeting on Monday morning.” But you might say: “Don’t worry if you’re busy, but it might be helpful if you could spare half an hour on Monday.”5 This deference makes sense in many situations, but it can be fatal when a 90-ton airplane is running out of fuel above a major city.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The problem was not a lack of diligence or motivation, but a system insensitive to the limitations of human psychology.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We will see that blame is, in many respects, a subversion of the narrative fallacy: an oversimplification driven by biases in the human brain. We will also see that it has subtle but measurable consequences, undermining our capacity to learn.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"if our first reaction is to assume that the person closest to a mistake has been negligent or malign, then blame will flow freely and the anticipation of blame will cause people to cover up their mistakes. But if our first reaction is to regard error as a learning opportunity, then we will be motivated to investigate what really happened.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is only when you look at the problem in the round that you glimpse how these contradictory perspectives can be reconciled and you can attempt something that an instantaneous blame game can never achieve: reform of the system. After all, if you don’t know what went wrong, how can you put things right?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Mistakes are made at businesses, hospitals, and government departments all the time. It is an inevitable part of our everyday interaction with a complex world. And yet if professionals think they are going to be blamed for honest mistakes, why would they be open about them? If they do not trust their managers to take the trouble to see what really happened, why would they report what is going wrong, and how can the system adapt? And the truth is that companies blame all the time. It is not just because managers instinctively jump to the blame response. There is also a more insidious reason: managers often feel that it is expedient to blame. After all, if a major company disaster can be conveniently pinned on a few “bad apples,” it may play better in PR terms. “It wasn’t us; it was them!” There is also a widespread management view that punishment can exert a benign disciplinary effect. It will make people sit up and take notice. By stigmatizing mistakes, by being tough on them, managers think that staff will become more diligent and motivated.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"These nurses in the so-called disciplined cultures may have been reporting fewer errors, but they were making more errors. In the low-blame teams, on the other hand, this finding was reversed. They were reporting more errors, but were making fewer errors overall.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"What was going on? The mystery was, in fact, easy to solve. It was precisely because the nurses in low-blame teams were reporting so many errors that they were learning from them, and not making the same mistakes again. Nurses in the high-blame teams were not speaking up because they feared the consequences, and so learning was being squandered.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"practice is about harnessing the benefits of learning from failure while reducing its cost. It is better to fail in practice in preparation for the big stage than on the big stage itself. This is true of organizations, too, that conduct pilot schemes (and in the case of aviation and other safety-critical industries test ideas in simulators) in order to learn, before rolling out new ideas or procedures. The more we can fail in practice, the more we can learn, enabling us to succeed when it really matters. But even if we practice diligently, we will still endure real-world failure from time to time. And it is often in these circumstances, when failure is most threatening to our ego, that we need to learn most of all. Practice is not a substitute for learning from real-world failure; it is complementary to it. They are, in many ways, two sides of the same coin.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This is a classic response predicted by cognitive dissonance: we tend to become more entrenched in our beliefs (like those in the capital punishment experiment, whose views became more extreme after reading evidence that challenged their views and the members of the cult who became more convinced of the truth of their beliefs after the apocalyptic prophecy failed). “I have no doubt that they will find the clearest possible evidence of Saddam’s weapons of mass destruction [my italics],” Blair said.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This doesn’t mean that blame is never justified. If, after investigation, it turns out that a person was genuinely negligent, then punishment is not only justifiable, but imperative. Professionals themselves demand this.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"If it is intolerable to change your mind, if no conceivable evidence will permit you to admit your mistake, if the threat to ego is so severe that the reframing process has taken on a life of its own, you are effectively in a closed loop. If there are lessons to be learned, it has become impossible to acknowledge them, let alone engage with them.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When the witnesses said they remembered seeing the suspect at the scene of the crime, they were telling the truth. They did remember seeing him there, but they didn’t actually see him there. These are two quite different things.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But the crucial point here is that justifiable blame does not undermine openness. Why? Because management has taken the time to find out what really happened rather than blaming preemptively, giving professionals the confidence that they can speak up without being penalized for honest mistakes. This is what is sometimes called a “just culture.” The question, according to Sidney Dekker, is not Who is to blame? It is not even Where, precisely, is the line between justifiable blame and an honest mistake? because this can never be determined in the abstract. Rather, the question is, Do those within the organization trust the people who are tasked with drawing that line? It is only when people trust those sitting in judgment that they will be open and diligent.8",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Self-justification is more insidious. Lying to oneself destroys the very possibility of learning. How can one learn from failure if one has convinced oneself – through the endlessly subtle means of self-justification, narrative manipulation, and the wider psychological arsenal of dissonance-reduction – that a failure didn’t actually occur?",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"In reality, however, she was guilty of a distinctive kind of laziness. By failing to engage with the complexity of the system she managed, she was blaming preemptively and thus undermining openness and learning. She was weakening the most important accountability of all: what the philosopher Virginia Sharpe calls “forward-looking accountability.” This is the accountability to learn from adverse events so that future patients are not harmed by avoidable mistakes.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When we are dealing with complexity, blaming without proper analysis is one of the most common as well as one of the most perilous things an organization can do. And it rests, in part, on the erroneous belief that toughness and openness are in conflict with each other. They are not.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In short, blame undermines the information vital for meaningful adaptation. It obscures the complexity of our world, deluding us into thinking we understand our environment when we should be learning from it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is worth noting here, if only briefly, the link between blame and cognitive dissonance. In a culture where mistakes are considered blameworthy they are also likely to be dissonant. When the external culture stigmatizes mistakes, professionals are likely to internalize these attitudes. Blame and dissonance, in effect, are driven by the same misguided attitude to error,",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is illegal in the UK to even conduct a study on how juries go about their deliberations. The unstated rationale for this prohibition is that if the public find out how juries operate, they might lose confidence in the system. It is an “ignorance is bliss” approach. But this is as intellectually fraudulent as removing the black box from an airplane to insure that people won’t ever find out about pilot error. The result is inevitable: the same mistakes will be made, over and over.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"And this takes us back to perhaps the most paradoxical aspect of cognitive dissonance. It is precisely those thinkers who are most renowned, who are famous for their brilliant minds, who have the most to lose from mistakes. And that is why it is often the most influential people, those who ought to be in the best position to help the world learn from new evidence, who have the greatest incentive to reframe it. And these are also the kinds of people (or institutions) who often have the capacity to employ expensive PR firms to bolster their post hoc justifications. They have the financial means, in addition to a powerful subconscious urge, to bridge the gap between beliefs and evidence, not by learning, but by spinning. It is the equivalent of a golfer hitting the ball out of bounds and then hiring a slick PR company to convince the world that it had nothing to do with him, it was a sudden gust of wind!",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In his seminal book, Why Smart Executives Fail: And What You Can Learn from Their Mistakes, Sydney Finkelstein, a management professor at Dartmouth College, investigated major failures at more than fifty corporate institutions. 11 He found that error-denial increases as you go up the pecking order. Ironically enough, the higher people are in the management hierarchy, the more they tend to supplement their perfectionism with blanket excuses, with CEOs usually being the worst of all. For example, in one organization we studied, the CEO spent the entire forty-five-minute interview explaining all the reasons why others were to blame for the calamity that hit his company. Regulators, customers, the government, and even other executives within the firm—all were responsible. No mention was made, however, of personal culpability. The reason should by now be obvious. It is those at the top of business who are responsible for strategy and therefore have the most to lose if things go wrong. They are far more likely to cling to the idea that the strategy is wise, even as it is falling apart, and to reframe any evidence that says otherwise. Blinded by dissonance, they are also the least likely to learn the lessons.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This approach is now the focus of a crusading group of economists who have transformed international development over the last decade. They do not come up with grand designs; rather, they look for small advantages. As Esther Duflo, the French-born economist who is at the forefront of this approach, put it: “If we don’t know if we are doing any good, we are not any better than the medieval doctors and their leeches. Sometimes the patient gets better; sometimes the patient dies. Is it the leeches or something else? We don’t know.”6",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Duflo, who is petite and dynamic, doesn’t regard her work as lacking in ambition; rather, she regards these incremental improvements as pioneering. She told me: It is very easy to sit back and come up with grand theories about how to change the world. But often our intuitions are wrong. The world is too complex to figure everything out from your armchair. The only way to be sure is to go out and test your ideas and programs, and to realize that you will often be wrong. But that is not a bad thing. It leads to progress.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Brailsford, Duflo and Vowles see weaknesses with a different set of eyes. Every error, every flaw, every failure, however small, is a marginal gain in disguise. This information is regarded not as a threat but as an opportunity. They are, in a sense, like aviation safety experts, who regard every near-miss event as a precious chance to avert an accident before it happens.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"As of 2010, the company was carrying out 12,000 RCTs every year. This is an astonishing amount of experimentation and it means that Google clocks up thousands of little failures. Each RCT may seem like nitpicking, but the cumulative effect starts to look very different.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Businesses now execute more RCTs than all other kinds of institutions combined,” he told me. “It is one of the biggest changes in corporate practice for a generation.”11",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Cumulative selection works, then, if there is some form of “memory”: i.e., if the results of one selection test are fed into the next, and into the next, and so on. This process is so powerful that, in the natural world, it confers what has been called “the illusion of design”: animals that look as if they were designed by a vast intelligence when they were, in fact, created by a blind process. An echo of this illusion can be seen in the nozzle example. The final shape is so uniquely suited to creating fine-grained detergent that it invites the thought that a master designer must have been at work. In fact, as we have seen, the biologists used no “design” capability at all. They simply harnessed the power of the evolutionary process.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Evolution as a process is powerful because of its cumulative nature. Richard Dawkins offers a neat way to think about cumulative selection in his wonderful book The Blind Watchmaker. He invites us to consider a monkey trying to type a single line from Hamlet: “Methinks it is like a weasel.” The odds are pretty low for the monkey to get it right. If the monkey is typing at random and there are 27 letters (counting the space bar as a letter), it has a 1 in 27 chance to get the first letter right, a 1 in 27 for the next letter, and so on. So just to get the first three in a row correct are 1/27 multiplied by 1/27 multiplied by 1/27. That is one chance in 19,683. To get all 28 in the sequence, the odds are around 1 in 10,000 million, million, million, million, million, million. But now suppose that we provide a selection mechanism (i.e., a failure test) that is cumulative. Dawkins set up a computer program to do just this. Its first few attempts at getting the phrase is random, just like a monkey. But then the computer scans the various nonsense phrases to see which is closest, however slightly, to the target phrase. It rejects all the others. It then randomly varies the winning phrase, and then scans the new generation. And so on. The winning phrase after the first generation of running the experiment on the computer was: WDLTMNLT DTJBSWIRZREZLMQCO P. After ten generations, by honing in on the phrase closest to the target phrase, and rejecting the others, it was: MDLDMNLS ITJISWHRZREZ MECS P. After twenty generations, it looked like this: MELDINLS IT ISWPRKE Z WECSEL. After thirty generations, the resemblance is visible to the naked eye: METHINGS IT ISWLIKE B WECSEL. By the forty-third generation, the computer got the right phrase. It took only a few moments to get there.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The greatest difficulty that many people face, as we have seen, is in admitting to their personal failures, and thus learning from them. We have looked at cognitive dissonance, which becomes so severe that we often reframe, spin, and sometimes even edit out our mistakes. Now think of the Unilever biologists. They didn’t regard the rejected nozzles as failures because they were part and parcel of how they learned. All those rejected designs were regarded as central to their strategy of cumulative selection, not as an indictment of their judgment. They knew they would have dozens of failures and were therefore not fazed by them. But when we are misled into regarding the world as simpler than it really is, we not only resist testing our top-down strategies and assumptions, we also become more defensive when they are challenged by our peers or by the data. After all, if the world is simple, you would have to be pretty stupid not to understand it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Although they competed against substantially larger, better-resourced companies . . . they were consistently first to identify new features and services such as driving directions and integrated web-phone promotional offers,” Peter Sims, the tech author who followed the company’s progress, has written. “As Vanier explains, if he can launch ten features in the same time it takes a competitor to launch one, he’ll have ten times the amount of experience to draw from in figuring out what has failed the test of customer acceptance and what has succeeded.”11",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The desire for perfection rests upon two fallacies. The first resides in the miscalculation that you can create the optimal solution sitting in a bedroom or ivory tower and thinking things through rather than getting out into the real world and testing assumptions, thus finding their flaws. It is the problem of valuing top-down over bottom-up. The second fallacy is the fear of failure. Earlier on we looked at situations where people fail and then proceed to either ignore or conceal those failures. Perfectionism is, in many ways, more extreme. You spend so much time designing and strategizing that you don’t get a chance to fail at all, at least until it is too late. It is pre-closed loop behavior. You are so worried about messing up that you never even get on the field of play.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Babineaux and Krumboltz, the two psychologists, have some advice for those who are prone to the curse of perfectionism. It involves stating the following mantras: “If I want to be a great musician, I must first play a lot of bad music.” “If I want to become a great tennis player, I must first lose lots of tennis games.” “If I want to become a top commercial architect known for energy-efficient, minimalist designs, I must first design inefficient, clunky buildings.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"One of the ironies of charitable spending is that the one statistic many donors do tend to look at can actually undermine the pursuit of evidence. The so-called overhead ratio measures the amount of money spent on administration compared with the front line. Most donors are keen for charities to keep this ratio low: they want money to go to those who really need it rather than office staff. But given that evidence-gathering counts as an administrative cost rather than treatment, this makes it even more difficult for charities to conduct tests.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Closed loops are often perpetuated by people covering up mistakes. They are also kept in place when people spin their mistakes, rather than confronting them head on. But there is a third way that closed loops are sustained over time: through skewed interpretation.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Looking at the sales statistics is not going to help you find an answer any more than looking at the number of people recovering from bloodletting will help you find out if the treatment is effective. The reason is simple: you can’t observe the counterfactual. You don’t know whether the change in sales was caused by something else; something, perhaps, you hadn’t even considered.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"doctors are sometimes oblivious to their mistakes because they have already reframed them. They are not dishonest people; they are often unaware of the reframing exercise because it is largely subconscious. If there were independent investigations into adverse events, these mistakes would be picked up during the “black box” analysis and doctors would be challenged on them, and learn from them. But proper independent investigation is almost nonexistent. Moreover, such investigations generally rely on the information provided by professionals, which is often withheld in a culture that stigmatizes error. This means that doctors make the same mistakes again and again, while growing in the mistaken conviction that they are infallible. This, in turn, increases the cognitive dissonance associated with mistakes, tightening the noose still further. Admitting to error becomes so threatening that in some cases surgeons (decent, honorable people) would rather risk killing a patient than admit they might be wrong.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Progress is often driven not by the accumulation of small steps, but by dramatic leaps. The television wasn’t an iteration of a previous device, it was a new technology altogether. Einstein’s general theory of relativity didn’t tinker with Newton’s law of universal gravitation, it replaced it in almost every detail.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"People think of creativity as a mystical process. The idea is that creative insights emerge from the ether, through pure contemplation. This model conceives of innovation as something that happens to people, normally geniuses. But this could not be more wrong. Creativity is something that has to be worked at, and it has specific characteristics. Unless we understand how it happens, we will not improve our creativity, as a society or as a world.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This idea percolated in Dyson’s mind for the next three years. A graduate of the Royal College of Art, he was already a qualified engineer and was helping to run a local company in Bath. He enjoyed pulling things apart and seeing how they worked. He was curious, inquisitive, and willing to engage with a difficulty rather than just accepting it. But now he had a live problem, one that intrigued him.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Anumber of things jump out about the Dyson story. The first is that the solution seems rather obvious in hindsight. This is often the case with innovation, and it’s something we will come back to. But now consider a couple of other aspects of the story. The first is that the creative process started with a problem, what you might even call a failure, in the existing technology. The vacuum cleaner kept blocking. It let out a screaming noise. Dyson had to keep bending down to pick up bits of trash by hand. Had everything been going smoothly Dyson would have had no motivation to change things. Moreover, he would have had no intellectual challenge to sink his teeth into. It was the very nature of the engineering problem that sparked a possible solution (a bagless vacuum cleaner). And this turns out to be an almost perfect metaphor for the creative process, whether it involves vacuum cleaners, a quest for a new brand name, or a new scientific theory. Creativity is, in many respects, a response.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This aspect of the creative process, the fact that it emerges in response to a particular difficulty, has spawned its own terminology. It is called the “problem phase” of innovation. “The damn thing had been bugging me for years,” Dyson says of the conventional vacuum cleaner. “I couldn’t bear the inefficiency of the technology. It wasn’t so much a ‘problem phase’ as a ‘hatred phase.’” We often leave this aspect of the creative process out of the picture. We focus on the moment of epiphany, the detonation of insight that happened when Newton was hit by the apple or Archimedes was taking a bath. That is perhaps why creativity seems so ethereal. The idea is that such insights could happen anytime, anywhere. It is just a matter of sitting back and letting them flow. But this leaves out an indispensable feature of creativity. Without a problem, without a failure, without a flaw, without a frustration, innovation has nothing to latch on to. It loses its pivot. As Dyson puts it: “Creativity should be thought of as a dialogue. You have to have a problem before you can have the game-changing riposte.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The failure of companies in a free market, then, is not a defect of the system, or an unfortunate by-product of competition; rather, it is an indispensable aspect of any evolutionary process. According to one economist, 10 percent of American companies go bankrupt every year.4 The economist Joseph Schumpeter called this “creative destruction.” Now, compare this with centrally planned economies, where there are almost no failures at all. Companies are protected from failure by subsidy. The state is protected from failure by the printing press, which can inflate its way out of trouble. At first, this may look like an enlightened way to go about solving the problems of economic production, distribution, and exchange. Nothing ever fails and, by implication, everything looks successful. But this is precisely why planned economies didn’t work. They were manned by intelligent planners who decided how much grain to produce, how much iron to mine, and who used complicated calculations to determine the optimal solutions. But they faced the same problem as the Unilever mathematicians: their ideas, however enlightened, were not tested rapidly enough—and so had little opportunity to be reformed in the light of failure. Even if the planners were ten times smarter than the businessmen operating in a market economy, they would still fall way behind. Without the benefit of a valid test, the system is plagued by rigidity. In markets, on the other hand, it is the thousands of little failures that lubricate and, in a sense, guide the system. When companies go under, other entrepreneurs learn from these mistakes, the system creates new ideas, and consumers ultimately benefit.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But the underlying point remains: markets work not in spite of the many business failures that occur, but because of them.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is not just systems that can benefit from a process of testing and learning; so, too, can organizations. Indeed, many of the most innovative companies in the world are bringing some of the basic lessons of evolutionary theory into the way they think about strategy. Few companies tinker randomly like the Unilever biologists, because with complex problems it can take a long time to home in on a solution. Rather, they make judicious use of tests, challenge their own assumptions, and wield the lessons to guide strategy. It is a mix of top-down reasoning (as per the mathematicians) and bottom-up iteration (as per the biologists); the fusing of the knowledge they already have with the knowledge that can be gained by revealing its inevitable flaws. It is about having the courage of one’s convictions, but also the humility to test early, and to adapt rapidly.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"these world-changing machines were developed, like Unilever’s nozzle, through trial and error. Amateurs and artisans, men of practical wisdom, motivated by practical problems, worked out how to build these machines, by trying, failing, and learning. They didn’t fully understand the theory underpinning their inventions. They couldn’t have talked through the science. But—like the Unilever biologists—they didn’t really need to.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"That is what happens in systems populated by human beings: there are unintended consequences. And this is why it is difficult to formulate an effective strategy from on high, via a blueprint.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In the coming decades, Professor Lane argues, success will not just be about intelligence and talent. These things are important; but they should never overshadow the significance of identifying where one’s strategy is going wrong, and evolving. Systems and organizations that foster the growth of knowledge of all kinds will dominate. This is the insight that the high-tech world has been gravitating toward and that much of the rest of the world, with only a few heroic exceptions, is studiously resisting.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is for this reason that many of the most influential development campaigners argue that the most important issue when it comes to charitable giving is not just raising more money, but conducting tests, understanding what is working and what isn’t, and learning. Instead of trusting in narrative, we should be wielding the power of the evolutionary mechanism.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"With these caveats in mind, then, RCTs offer a powerful method of establishing rigorous tests in a complex world. Handled with care, they cut through the ambiguity that can play havoc with our interpretation of feedback. And they are often simple to conduct. Take the example of the redesigned website mentioned earlier. The problem was in establishing whether the change in the design had increased sales, or was caused by something else. But suppose you randomly direct users to either the new or the old design. You could then measure whether they buy more goods from the former or the latter. This would filter out all the other influences such as interest rates, competition, weather and so on, and reveal the hidden counterfactual.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Closed loops are not merely an intellectual curiosity, they realistically describe the world we live in. They are small and large, subtle and intricate; they lurk in small companies, big companies, charities, corporations and governments. The majority of our assumptions have never been subject to robust failure tests. Unless we do something about it they never will be.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Scared Straight was, in many ways, ahead of its time. Unlike most social programs, which collate no data whatsoever, it actually sent out questionnaires and gathered statistics. But, as with medieval bloodletting, observational stats do not always provide reliable data. Often, you need to test the counterfactual. Otherwise you may be harming people without even realizing it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Contradictory information jars, in much the same way that error jars. It encourages us to engage in a new way. We start to reach beyond our usual thought processes (why would you think differently when things are going just as expected?). When someone shouts out the wrong color, our conventional mental operations are disrupted. That is when we find associations, connections, that might never have occurred to us.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The eureka moment is not the endpoint of innovation, it is the start of perhaps the most fascinating stage of all.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Dyson strode into his workshop. He had come up with his big idea: a bagless vacuum cleaner where dust is removed from the air by the geometry of the airflow rather than a filter. But he was pretty much alone. The directors at his company didn’t back his idea (the response he received was: “If that is such a good concept, how come Hoover and Electrolux aren’t doing it already?”), so he started his own business along with a silent partner, who had provided half the capital.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"With each iteration he was learning new things. He was seeing what worked. Most of the time he was failing. “A cyclone has a number of variables: size of entry, exit, angle, diameter, length: and the trying thing is that if you change one dimension, it affects all the others.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"In all, it took an astonishing 5,127 prototypes before Dyson believed the technology was ready to go in the vacuum cleaner. The creative leap may have been a crucial and precious thing, but it was only the start of the creative process. The real hard yards were done patiently evolving the design via bottom-up iteration. To put it another way, with the epiphany he had vaulted onto a taller mountain in a new landscape; now he was systematically working toward this new summit.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"When you file a patent, somebody is almost always there before you. A lot of your argument with the patent examiner is to say: “Look, they may have had the eureka moment when they came back from the timber yard. They may even have created an early prototype.” But none of my forebears had made their prototypes work. Mine is statistically different. That was my decisive advantage. Creativity, then, has a dual aspect. Insight often requires taking a step back and seeing the big picture. It is about drawing together disparate ideas. It is the art of connection. But to make a creative insight work requires disciplined focus. As Dyson puts it: “If insight is about the big picture, development is about the small picture. The trick is to sustain both perspectives at the same time.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This finding is by no means unusual. In their book Will and Vision, Gerard J. Tellis and Peter N. Golder looked at the relationship between long-term market leadership and pioneering innovation in sixty-six different commercial sectors. They found that only 9 percent of the pioneers ended up as the final winners. They also found that 64 percent of pioneers failed outright.16",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Dyson, Catmull, and the other innovators we have encountered offer a powerful rebuke to the way we conventionally think about creativity. To spark the imagination and take our insights to their fullest expression, we should not insulate ourselves from failure; rather, we should engage with it.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The problem with academia is that it is about being good at remembering things like chemical formulae and theories, because that is what you have to regurgitate. But children are not allowed to learn through experimenting and experience. This is a great pity. You need both.” One of the most powerful aspects of the Dyson story is that it evokes a point that was made in chapter 7; namely, that technological change is often driven by the synergy between practical and theoretical knowledge. One of the first things Dyson did when he had the insight for a cyclone cleaner was to buy two books on the mathematical theory of how cyclones work. He also went to visit the author of one of those books, an academic named R. G. Dorman.22 This was hugely helpful to Dyson. It allowed him to understand cyclone dynamics more fully. It played a role in directing his research and gave him a powerful background on the mathematics of separation efficiency. But it was by no means sufficient. The theory was too abstract to lead him directly to the precise dimensions that would deliver a functional vacuum cleaner. Moreover, as Dyson iterated his device, he discovered that the theory had flaws. Dorman’s equation predicted that cyclones would only be able to remove fine dust down to a lower limit of 20 microns. But Dyson quickly broke through this theoretical limit. By the end, his cyclone could separate dust smaller than 0.3 micron (this is approximately the size of the particles in cigarette smoke). Dyson’s practical engagement with the problem had forced a change in the theory. And this is invariably how progress happens. It is an interplay between the practical and the theoretical, between top-down and bottom-up, between creativity and discipline, between the small picture and the big picture. The crucial point—and the one that is most dramatically overlooked in our culture—is that in all these things, failure is a blessing, not a curse. It is the jolt that inspires creativity and the selection test that drives evolution.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Andrew Stanton, director of Finding Nemo and WALL-E, has said: My strategy has always been: be wrong as fast as we can . . . which basically means, we’re gonna screw up, let’s just admit that. Let’s not be afraid of that. But let’s do it as fast as we can so we can get to the answer. You can’t get to adulthood before you go through puberty. I won’t get it right the first time, but I will get it wrong really soon, really quickly.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Memory, it turns out, is not as reliable as we think. We do not encode high-definition movies of our experiences and then access them at will. Rather, memory is a system dispersed throughout the brain and is subject to all sorts of biases. Memories are suggestible. We often assemble fragments of entirely different experiences and weave them together into what seems like a coherent whole. With each recollection, we engage in editing.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Feedback, when delayed, is considerably less effective in improving intuitive judgment.*",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"anymore. Why would they? There is a lot to learn in science without studying all the ideas that have been jettisoned over time. But this tendency creates a blind spot. By looking only at the theories that have survived, we don’t notice the failures that made them possible. This blind spot is not limited to science; it is a basic property of our world and it accounts, to a large extent, for our skewed attitude to failure. Success is always the tip of an iceberg. We learn vogue theories, we fly in astonishingly safe aircraft, we marvel at the virtuosity of true experts. But beneath the surface of success—outside our view, often outside our awareness—is a mountain of necessary failure.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Toyota has a rather unusual production process. If anybody on the production line is having a problem or observes an error, that person pulls a cord that halts production across the plant. Senior executives rush over to see what has gone wrong and, if an employee is having difficulty performing her job, she is helped as needed by executives. The error is then assessed, lessons learned, and the system adapted. It is called the Toyota Production System, or TPS, and is one of the most successful techniques in industrial history. “The system was about cars, which are very different from people,” Kaplan says when we meet for an interview. “But the underlying principle is transferable. If a culture is open and honest about mistakes, the entire system can learn from them. That is the way you gain improvements.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"incentives to improve performance can only have an impact, in many circumstances, if there is a prior understanding of how improvement actually happens. Think back to medieval doctors who killed patients, including their own family members, with bloodletting. This happened not because they didn’t care but because they did care. They thought the treatment worked. They trusted in the authority of Galen rather than trusting in the power of criticism and experimentation to reveal the inevitable flaws in his ideas, thus setting the stage for progress. Unless we alter the way we conceptualize failure, incentives for success can often be impotent.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The problem is not that the information doesn’t exist; rather, it is the way it is formatted. As Atul Gawande, a doctor and author, puts it: The reason . . . is not usually laziness or unwillingness. The reason is more often that the necessary knowledge has not been translated into a simple, usable and systematic form. If the only thing people did in aviation was issue dense, pages-long bulletins . . . it would be like subjecting pilots to the same deluge of almost 700,000 medical journal articles per year that clinicians must contend with. The information would be unmanageable. Instead . . . crash investigators [distill] the information into its practical essence.30",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"this takes us to the deepest irony of all. When the probability of error is high, the importance of learning from mistakes is more essential, not less. As Professor James Reason, one of the world’s leading experts on system safety, put it: “This is the paradox in a nutshell: health care by its nature is highly error-provoking—yet health workers stigmatize fallibility and have had little or no training in error management or error detection.”35",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"there are also two kinds of error. The first is when a doctor diagnoses a tumor that isn’t actually there. This is sometimes called a Type One error: an error of commission. The second kind is when a doctor fails to diagnose a tumor that is there. This is called a Type Two error: an error of omission. It is possible to reduce one kind of error while simultaneously increasing the other kind by altering the “evidence threshold,” as in the criminal justice system. But this trade-off should not obscure the fact that it is possible to reduce both kinds of error at the same time. That is what progress is ultimately about.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It is noteworthy that when a court of criminal appeal was first proposed in England and Wales in the early nineteenth century, the strongest opponents were judges. The court had a simple rationale: to provide an opportunity for redress. It was an institutional acknowledgment that mistakes were possible. The judges were against it, in large part, because they denied the premise. The creation of the court turned out to be “one of the longest and hardest fought campaigns in the history of law reform” requiring “thirty-one parliamentary bills over a sixty year period.”4",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"DNA testing is to justice what the telescope is for the stars: not a lesson in biochemistry, not a display of the wonders of magnifying optical glass, but a way to see things as they really are,” Scheck has said. “It is a revelation machine.”7",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"By 2005 more than three hundred people had had their convictions overturned following DNA tests.11 In situations where evidence had been stored, clients of the Innocence Project (a nonprofit group that helps prisoners protesting their innocence) were exonerated in almost half the cases.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Estimates are difficult to establish, but a study led by Samuel R. Gross, a professor at the University of Michigan Law School, concluded: “If we reviewed prison sentences with the same level of care that we devote to death sentences, there would have been over 28,500 non-death-row exonerations [in the United States] in the past 15 years rather than the 255 that have in fact occurred.”12",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Cognitive dissonance” is the term Festinger coined to describe the inner tension we feel when, among other things, our beliefs are challenged by evidence.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Think about it in terms of cognitive dissonance. If I have put up with a lot to become a member of a group, if I have voluntarily subjected myself to acute embarrassment, I would have to be pretty stupid if the group turned out to be anything less than wonderful. To protect my self-esteem I will want to convince myself that the group is pretty damn good. Hence the necessity to talk it up, to reframe my perceptions in a positive direction. None of this applies, of course, if the initiation is simple. If the group turns out to be a waste of time, one can say to oneself honestly, and without any threat to one’s self-esteem, “This place is not worth bothering with.” It is only when we have staked our ego that our mistakes of judgment become threatening. That is when we build defensive walls and deploy cognitive filters.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Festinger’s great achievement was to show that cognitive dissonance is a deeply ingrained human trait. The more we have riding on our judgments, the more we are likely to manipulate any new evidence that calls them into question.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Dyson’s innovation, stripped down to its essentials, was to merge them. He was a connecting agent. The act of creativity was an act, above all, of synthesis. “I think the fact that I had so many years of frustration probably made me the perfect person to glimpse a possible solution,” he says. “But the solution was really about combining two existing technologies.” And it turns out that this act of connectivity is another central feature of innovation. Johannes Gutenberg invented mass printing by applying the pressing of wine (the technology of which had existed for many centuries) to the pressing of pages.6 The Wright brothers applied their understanding of manufacturing bicycles to the problem of powered flight.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Imagine what it must be like to be confronted with evidence that they have assisted in putting the wrong person in jail; that they have ruined the life of an innocent person; that the wounds of the victim’s family are going to be reopened. It must be stomach churning. In terms of cognitive dissonance, it is difficult to think of anything more threatening.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But notice the contrast here. When prosecutors are assessing evidence at the beginning of a case, DNA is held up as the most powerful evidence there is. That is why it has helped to secure so many convictions. But once prosecutors have secured a conviction, exonerating DNA evidence suddenly becomes highly suspect. Why is this? Festinger would have found it pretty easy to explain: DNA evidence is indeed strong, but not as strong as the desire to protect one’s self-esteem.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"What was the key ingredient that characterized the winners, the companies that may not have come up with an idea first, but who made it work? The answer can be conveyed in one word: discipline. This is not just the discipline to iterate a creative idea into a rigorous solution; it is also the discipline to get the manufacturing process perfect, the supply lines faultless, and delivery seamless.* Dyson was not the first to come up with the idea of a cyclone vacuum cleaner. He was not even the second, or the third. But he was the only one with the stamina to “fail” his concept into a workable solution. And he had the rigor to create an efficient manufacturing process, so he could sell a consistent product. His competitors confronted the same problem and had the same insight. But they didn’t have the same resilience to make their idea work, let alone take it on to a working production line.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We learn not just by being correct, but also by being wrong. It is when we fail that we learn new things, push the boundaries, and become more creative. Nobody had a new insight by regurgitating information, however sophisticated. Dyson says: We live in a world of experts. There is nothing particularly wrong with that. The expertise we have developed is crucial for all of us. But when we are trying to solve new problems, in business or technology, we need to reach beyond our current expertise. We do not want to know how to apply the rules; we want to break the rules. We do that by failing—and learning.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"is this structure that is so marvelously evoked by the Unilever example. What the development of the nozzle reveals, above all, is the power of testing. Even though the biologists knew nothing about the physics of phase transition, they were able to develop an efficient nozzle by trialing lots of different ones, rejecting those that didn’t work and then varying the best nozzle in each generation. It is not coincidental that the biologists chose this strategy: it mirrors how change happens in nature. Evolution is a process that relies on a “failure test” called natural selection. Organisms with greater “fitness” survive and reproduce, with their offspring inheriting their genes subject to a random process known as mutation. It is a system, like the one that created the Unilever nozzle, of trial and error.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"These examples do not show that theoretical knowledge is worthless. Quite the reverse. A conceptual framework is vital even for the most practical men going about their business. In many circumstances, new theories have led to direct technological breakthroughs (such as the atom bomb emerging from the Theory of Relativity). The real issue here is speed. Theoretical change is itself driven by a feedback mechanism, as we noted in chapter 3: science learns from failure. But when a theory fails, like say when the Unilever mathematicians failed in their attempt to create an efficient nozzle design, it takes time to come up with a new, all-encompassing theory. To gain practical knowledge, however, you just need to try a different-sized aperture. Tinkering, tweaking, learning from practical mistakes: all have speed on their side. Theoretical leaps, while prodigious, are far less frequent.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"But artificial intelligence has moved on since then.7 One of the vogue ideas is called temporal difference learning. When designers created TD-Gammon, a program to play backgammon, they did not provide it with any preprogrammed chess knowledge or capacity to conduct deep searches. Instead, it made moves, predicted what would happen next, and then looked at how far its expectations were wide of the mark. That enabled it to update its expectations, which it took into the next game. In effect, TD-Gammon was a trial-and-error program. It was left to play day and night against itself, developing practical knowledge. When it was let loose on human opponents, it defeated the best in the world. The software that enabled it to learn from error was sophisticated, but its main strength was that it didn’t need to sleep, so could practice all the time.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"It turns out, however, that there is a profound obstacle to testing, a barrier that prevents many of us from harnessing the upsides of the evolutionary process. It can be summarized simply, although the ramifications are surprisingly deep: we are hardwired to think that the world is simpler than it really is. And if the world is simple, why bother to conduct tests? If we already have the answers, why would we feel inclined to challenge them?",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"That is the power of the narrative fallacy. We are so eager to impose patterns upon what we see, so hardwired to provide explanations that we are capable of “explaining” opposite outcomes with the same cause without noticing the inconsistency.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"If we view the world as simple, we are going to expect to understand it without the need for testing and learning. The narrative fallacy, in effect, biases us toward top-down rather than bottom-up. We are going to trust our hunches, our existing knowledge, and the stories that we tell ourselves about the problems we face, rather than testing our assumptions, seeing their flaws, and learning.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Confirmation bias is another of the psychological quirks associated with cognitive dissonance. The best way to see its effects is to consider the following sequence of numbers: 2, 4, 6. Suppose that you have to discover the underlying pattern in this sequence. Suppose, further, that you are given an opportunity to propose alternative sets of three numbers to explore the possibilities. Most people playing this game come up with a hypothesis pretty quickly. They guess, for example, that the underlying pattern is “even numbers ascending sequentially.” There are other possibilities, of course. The pattern might just be “even numbers.” Or “the third number is the sum of the first two.” And so on. The key question is, How do you establish whether your initial hunch is right? Most people simply try to confirm their hypothesis. So, if they think the pattern is “even numbers ascending sequentially,” they will propose “10, 12, 14” and when this is confirmed, they will propose “100, 102, 104.” After three such tests most people are pretty certain that they have found the answer. And yet they may be wrong. If the pattern is actually “any ascending numbers,” their guesses will not help them. Had they used a different strategy, on the other hand, attempting to falsify their hypothesis rather than confirm it, they would have discovered this far quicker. If they had, say, proposed 4, 6, 11 (fits the pattern), they would have found that their initial hunch was wrong. If they had followed up with, say, 5, 2, 1, (which doesn’t fit), they would now be getting pretty warm. As Paul Schoemaker, research director of the Mack Institute for Innovation Management at the Wharton School of the University of Pennsylvania, puts it: The pattern is rarely uncovered unless subjects are willing to make mistakes—that is, to test numbers that violate their belief. Instead most people get stuck in a narrow and wrong hypothesis, as often happens in real life, such that their only way out is to make a mistake that turns out not to be a mistake after all. Sometimes, committing errors is not just the fastest way to the correct answer; it’s the only way.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Cognitive dissonance occurs when mistakes are too threatening to admit to, so they are reframed or ignored. This can be thought of as the internal fear of failure: how we struggle to admit mistakes to ourselves.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"But this visualization also reveals the inherent limitations of marginal gains. Often in business, technology, and life, progress is not about small, well-delivered steps, but creative leaps. It is about acts of imagination that can transform the entire landscape of a problem. Indeed, these are sometimes the most important drivers of change in the modern world.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"There is an ongoing debate in the political, scientific, and business worlds about whether to focus on the bold leaps that lead to new conceptual terrain, or on the marginal gains that help to optimize one’s existing fundamental assumptions. Is it about testing small assumptions or big ones; is it about transforming the world or tweaking it; is it about considering the big picture (the so-called gestalt) or the fine detail (the margins)? The simple answer, however, is that it has to be both. At the level of the system and, increasingly, at the level of the organization, success is about developing the capacity to think big and small, to be both imaginative and disciplined, to immerse oneself in the minutiae of a problem and to stand beyond it in order to glimpse the wider vista.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Further studies have shown that those who dissent rather than brainstorm produce not just more ideas, but more productive and imaginative ideas. As Nemeth put it: “The basic finding is that the encouragement of debate—and even criticism if warranted—appears to stimulate more creative ideas. And cultures that permit and even encourage such expression of differing viewpoints may stimulate the most innovation.” The reason is not difficult to identify. The problem with brainstorming is not its insistence on free-wheeling or quick association. Rather, it is that when these ideas are not checked by the feedback of criticism, they have nothing to respond to. Criticism surfaces problems. It brings difficulties to light. This forces us to think afresh. When our assumptions are violated we are nudged into a new relationship with reality. Removing failure from innovation is like removing oxygen from a fire.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Imagination is not fragile. It feeds off flaws, difficulties, and problems. Insulating ourselves from failures—whether via brainstorming guidelines, the familiar cultural taboo on criticism, or the influence of cognitive dissonance*—is to rob one of our most valuable mental faculties of fuel. “It always starts with a problem,” Dyson says. “I hated vacuum cleaners for twenty years, but I hated hand dryers for even longer. If they had worked perfectly, I would have had no motivation to come up with a new solution. But more important, I would not have had the context to offer a creative solution. Failures feed the imagination. You cannot have the one without the other.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Little wonder that Steve Jobs, a master in the art of merging concepts, once said: “Creativity is just connecting things.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"If failure sparks creativity into life, the moment of insight invariably emerges from the attempt to bridge the problem with previously unconnected ideas or technologies. It is about finding a hidden connection in order to solve a problem with meaning. But the crucial point to realize is that these processes are intimately intertwined. It is precisely because we have been hit by jarring information that we are nudged into looking for unusual connections, as we saw in the free association experiment.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"To put it simply, failure and epiphany are inextricably linked. When we come up with a brilliant idea, when it pops into our mind, it has often emerged from a period of gestation. It is a consequence of engaging with a problem, sometimes, as in the case of Dyson, for many years.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"This brief jaunt through the literature on creativity reveals one thing above all else: innovation is highly context-dependent. It is a response to a particular problem at a particular time and place. Take away the context, and you remove both the spur to innovation, and its raw material.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"And that is why the seductive idea that if Einstein had been born three hundred years earlier, we could have had the benefit of the theory of relativity in the seventeenth century is so flawed. Relativity couldn’t have happened back then, largely because the problems that it responded to were not yet visible. Einstein may have seen further and deeper than his contemporaries (there is still a large role for individualism: Einstein really was a creative genius), but he wasn’t pulling insights out of the ether. As Johnson writes: “Good ideas are not conjured out of thin air.” Dyson is well aware of this aspect of creativity. “Every time I have gone for a patent in a particular field, someone else has got there first,” he says. “I don’t think there has been a single time in all the thousands of patents we have applied for where we were the first. With the vacuum cyclone, there were already a number of patents lodged.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
Dyson says: It is no good creating the most beautiful products if you produce them shoddily. It is no good having the most innovative engineering solution if the consumers can’t be certain it will be delivered on time. It is no good if inconsistent production means that a great idea is not translated into a polished product. The original idea is only 2 percent of the journey. You mustn’t neglect the rest.,Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Winners require innovation and discipline, the imagination to see the big picture and the focus to perceive the very small. “The great task, rarely achieved, is to blend creative intensity with relentless discipline so as to amplify the creativity rather than destroy it,” Collins writes. “When you marry operating excellence with innovation, you multiply the value of your creativity.”19",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Catmull says: Early on, all of our movies suck. That’s a blunt assessment, I know, but I . . . choose that phrasing because saying it in a softer way fails to convey how bad the first versions of our films really are. I’m not trying to be modest or self-effacing by saying this. Pixar films are not good at first, and our job is to make them go . . . from suck to non-suck . . . We are true believers in the power of bracing, candid feedback and the iterative process—reworking, reworking and reworking again, until a flawed story finds its throughline or a hollow character finds its soul.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"The first is that you have to take into account all the data, including the data you cannot immediately see, if you are going to learn from adverse incidents. But",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"Jim Collins writes: ‘Gillette didn’t pioneer the safety razor, Star did. Polaroid didn’t pioneer the instant camera, Dubroni did. Microsoft didn’t pioneer the personal computer spreadsheet, VisiCorp did. Amazon didn’t pioneer online bookselling and AOL didn’t pioneer online internet service.’17 What",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"There is an ongoing debate in the political, scientific and business world about whether to focus on the bold leaps that lead to new conceptual terrain, or on the marginal gains that help to optimise one’s existing fundamental assumptions. Is it about testing small assumptions or big ones; is it about transforming the world or tweaking it; is it about considering the big picture (the so-called gestalt) or the fine detail (the margins)?",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"These words of Sullenberger are worth reflecting upon because they offer the chance to radically reimagine failure. The idea that the successful safety record in aviation has emerged from the rubble of real-world accidents is vivid, paradoxical, and profound. It is also revelatory. For if one looks closely enough it is an insight echoed across almost every branch of human endeavor.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Take science, a discipline where learning from failure is part of the method. This is a point that has been made by the philosopher Karl Popper, who suggested that science progresses through its vigilant response to its own mistakes. By making predictions that can be tested, a scientific theory is inherently vulnerable. This may seem like a weakness, but Popper realized that it is an incalculable strength. “The history of science, like the history of all human ideas, is a history of . . . error,” Popper wrote. “But science is one of the very few human activities—perhaps the only one—in which errors are systematically criticized and fairly often, in time, corrected. This is why we can say that, in science, we learn from our mistakes and why we can speak clearly and sensibly about making progress.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Science has often been regarded as a quest for confirmation. Scientists observe nature, create theories, and then seek to prove them by amassing as much supporting evidence as possible. But we can now see that this is only a part of the truth. Science is not just about confirmation, it is also about falsification. Knowledge does not progress merely by gathering confirmatory data, but by looking for contradictory data.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Failure, then, is hardwired into both the logic and spirit of scientific progress. Mankind’s most successful discipline has grown by challenging orthodoxy and by subjecting ideas to testing. Individual scientists may sometimes be dogmatic but, as a community, scientists recognize that theories, particularly those at the frontiers of our knowledge, are often fallible or incomplete. It is by testing our ideas, subjecting them to failure, that we set the stage for growth.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"Why is this? How can experience be so valuable in some professions but almost worthless in others? To see why, suppose that you are playing golf. You are out on the driving range, hitting balls toward a target. You are concentrating, and every time you fire the ball wide you adjust your technique in order to get it closer to where you want it to go. This is how practice happens in sport. It is a process of trial and error. But now suppose that instead of practicing in daylight, you practice at night—in the pitch-black. In these circumstances, you could practice for ten years or ten thousand years without improving at all. How could you progress if you don’t have a clue where the ball has landed? With each shot, it could have gone long, short, left, or right. Every shot has been swallowed by the night. You wouldn’t have any data to improve your accuracy. This metaphor solves the apparent mystery of expertise. Think about being a chess player. When you make a poor move, you are instantly punished by your opponent. Think of being a clinical nurse. When you make a mistaken diagnosis, you are rapidly alerted by the condition of the patient (and by later testing). The intuitions of nurses and chess players are constantly checked and challenged by their errors. They are forced to adapt, to improve, to restructure their judgments. This is a hallmark of what is called deliberate practice. For psychotherapists things are radically different. Their job is to improve the mental functioning of their patients. But how can they tell when their interventions are going wrong or, for that matter, right? Where is the feedback? Most psychotherapists gauge how their clients are responding to treatment not with objective data, but by observing them in clinic. But these data are highly unreliable. After all, patients might be inclined to exaggerate how well they are to please the therapist, a well-known issue in psychotherapy. But there is a deeper problem. Psychotherapists rarely track their clients after therapy has finished. This means that they do not get any feedback on the lasting impact of their interventions. They have no idea if their methods are working or failing—if the client’s long-term mental functioning is actually improving. And that is why the clinical judgments of many practitioners don’t improve over time. They are effectively playing golf in the dark.11",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"We learn not just by being correct, but also by being wrong. It is when we fail that we learn new things, push the boundaries, and become more creative. Nobody had a new insight by regurgitating information, however sophisticated. Dyson",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"The problem with academia is that it is about being good at remembering things like chemical formulae and theories, because that is what you have to regurgitate. But children are not allowed to learn through experimenting and experience. This is a great pity. You need both.’ One",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"A manager who takes the time to probe the data and who listens to the various perspectives has a crucial advantage. Not only does he figure out what really happened in the specific case, he also sends an empowering message to his staff: if you make an honest mistake we will not penalise you.",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"It is both apt and revealing that Sullenberger, a modest and self-evidently decent man, has made exactly this point. In a television interview months after the miracle landing on the Hudson, he offered this beautiful gem of wisdom: Everything we know in aviation, every rule in the rule book, every procedure we have, we know because someone somewhere died . . . We have purchased at great cost, lessons literally bought with blood that we have to preserve as institutional knowledge and pass on to succeeding generations. We cannot have the moral failure of forgetting these lessons and have to relearn them.",Black Box Thinking: Why Most People Never Learn from Their Mistakes--But Some Do,Matthew Syed,[]
"it is pretty much impossible to come up with perfect code first time around. It is only when people are using the software, putting it under strain, that you see the bugs and deficiencies you could never have anticipated. By putting the code out there and subjecting it to trial and error you learn the insights that create progress. Why, he asked Vanier, would you try to answer every question before you have a single user?",Black Box Thinking: The Surprising Truth About Success,Matthew Syed,[]
"...innovation is highly context-dependent. It is a response to a particular problem at a particular time and place. Take away the context, and you remove both the spur to innovation, and its raw material.",Black Box Thinking: Why Some People Never Learn from Their Mistakes - But Some Do,Matthew Syed,"['creativity', 'innovation', 'problem-solving']"
